{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-04-18T11:19:41.203692Z",
     "iopub.status.busy": "2022-04-18T11:19:41.203064Z",
     "iopub.status.idle": "2022-04-18T11:20:52.20679Z",
     "shell.execute_reply": "2022-04-18T11:20:52.206178Z",
     "shell.execute_reply.started": "2022-04-18T11:19:41.203601Z"
    }
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T11:21:59.001847Z",
     "iopub.status.busy": "2022-04-18T11:21:59.001186Z",
     "iopub.status.idle": "2022-04-18T11:22:08.70888Z",
     "shell.execute_reply": "2022-04-18T11:22:08.708063Z",
     "shell.execute_reply.started": "2022-04-18T11:21:59.001805Z"
    }
   },
   "outputs": [],
   "source": [
    "pip install nibabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T11:22:12.062747Z",
     "iopub.status.busy": "2022-04-18T11:22:12.062225Z",
     "iopub.status.idle": "2022-04-18T11:22:21.618688Z",
     "shell.execute_reply": "2022-04-18T11:22:21.617835Z",
     "shell.execute_reply.started": "2022-04-18T11:22:12.062706Z"
    }
   },
   "outputs": [],
   "source": [
    "pip install split-folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T11:22:25.687746Z",
     "iopub.status.busy": "2022-04-18T11:22:25.687479Z",
     "iopub.status.idle": "2022-04-18T11:22:25.889172Z",
     "shell.execute_reply": "2022-04-18T11:22:25.888409Z",
     "shell.execute_reply.started": "2022-04-18T11:22:25.687716Z"
    }
   },
   "outputs": [],
   "source": [
    "import nibabel as nib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T11:22:28.944838Z",
     "iopub.status.busy": "2022-04-18T11:22:28.944161Z",
     "iopub.status.idle": "2022-04-18T11:22:28.948605Z",
     "shell.execute_reply": "2022-04-18T11:22:28.947613Z",
     "shell.execute_reply.started": "2022-04-18T11:22:28.944799Z"
    }
   },
   "outputs": [],
   "source": [
    "# TRAIN_DATASET_PATH = 'BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/'\n",
    "#VALIDATION_DATASET_PATH = 'BraTS2020_ValidationData/MICCAI_BraTS2020_ValidationData'\n",
    "# TRAIN_DATASET_PATH = \"../input/brats20-dataset-training-validation/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/\"\n",
    "# path_masks = \"../input/brain-tumor-dataset-with-saliency/masks\"\n",
    "\n",
    "# test_image_flair=nib.load(TRAIN_DATASET_PATH + 'BraTS20_Training_100/BraTS20_Training_100_flair.nii').get_fdata()\n",
    "# print(test_image_flair.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T11:22:35.229942Z",
     "iopub.status.busy": "2022-04-18T11:22:35.229235Z",
     "iopub.status.idle": "2022-04-18T11:22:54.407742Z",
     "shell.execute_reply": "2022-04-18T11:22:54.406878Z",
     "shell.execute_reply.started": "2022-04-18T11:22:35.229904Z"
    }
   },
   "outputs": [],
   "source": [
    "pip install MedPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T11:22:57.758883Z",
     "iopub.status.busy": "2022-04-18T11:22:57.758614Z",
     "iopub.status.idle": "2022-04-18T11:23:06.664181Z",
     "shell.execute_reply": "2022-04-18T11:23:06.663403Z",
     "shell.execute_reply.started": "2022-04-18T11:22:57.758853Z"
    }
   },
   "outputs": [],
   "source": [
    "pip install --upgrade scipy --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-18T11:24:55.210082Z",
     "iopub.status.busy": "2022-04-18T11:24:55.209727Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "All BraTS multimodal scans are available as NIfTI files (.nii.gz) -> commonly used medical imaging format to store brain imagin data obtained using MRI and describe different MRI settings\n",
    "T1: T1-weighted, native image, sagittal or axial 2D acquisitions, with 1–6 mm slice thickness.\n",
    "T1ce: T1-weighted, contrast-enhanced (Gadolinium) image, with 3D acquisition and 1 mm isotropic voxel size for most patients.\n",
    "T2: T2-weighted image, axial 2D acquisition, with 2–6 mm slice thickness.\n",
    "FLAIR: T2-weighted FLAIR image, axial, coronal, or sagittal 2D acquisitions, 2–6 mm slice thickness.\n",
    "#Note: Segmented file name in Folder 355 has a weird name. Rename it to match others.\n",
    "\"\"\"\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import glob\n",
    "import random\n",
    "# from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "from tifffile import imsave\n",
    "from skimage import img_as_float\n",
    "from skimage.metrics import peak_signal_noise_ratio\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage import io\n",
    "from scipy import ndimage as nd\n",
    "from skimage.restoration import (denoise_tv_chambolle, denoise_bilateral,denoise_wavelet, estimate_sigma)\n",
    "from medpy.filter.smoothing import anisotropic_diffusion\n",
    "from scipy.signal import wiener\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from skimage.metrics import mean_squared_error\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from scipy.signal import convolve2d as conv2\n",
    "from skimage import color, data, restoration\n",
    "from PIL import Image\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##########################\n",
    "#This part of the code to get an initial understanding of the dataset.\n",
    "#################################\n",
    "#PART 1: Load sample images and visualize\n",
    "#Includes, dividing each image by its max to scale them to [0,1]\n",
    "#Converting mask from float to uint8\n",
    "#Changing mask pixel values (labels) from 4 to 3 (as the original labels are 0, 1, 2, 4)\n",
    "#Visualize\n",
    "###########################################\n",
    "#View a few images\n",
    "\n",
    "#Note: Segmented file name in Folder 355 has a weird name. Rename it to match others.\n",
    "\n",
    "\n",
    "# Setting up of image path and scaling the image\n",
    "\n",
    "# TRAIN_DATASET_PATH = 'BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/'\n",
    "TRAIN_DATASET_PATH = \"../input/brats-2d/Brats_2d/images_t1ce/\"\n",
    "#VALIDATION_DATASET_PATH = 'BraTS2020_ValidationData/MICCAI_BraTS2020_ValidationData'\n",
    "\n",
    "\n",
    "gaussian_cleaned_psnr_t1ce=[]\n",
    "gaussian_cleaned_mse_t1ce=[]\n",
    "gaussian_cleaned_ssim_t1ce=[]\n",
    "\n",
    "bilateral_cleaned_psnr_t1ce=[]\n",
    "bilateral_cleaned_mse_t1ce=[]\n",
    "bilateral_cleaned_ssim_t1ce=[]\n",
    "\n",
    "aniso_cleaned_psnr_t1ce=[]\n",
    "aniso_cleaned_mse_t1ce=[]\n",
    "aniso_cleaned_ssim_t1ce=[]\n",
    "\n",
    "wiener_cleaned_psnr_t1ce=[]\n",
    "wiener_cleaned_mse_t1ce=[]\n",
    "wiener_cleaned_ssim_t1ce=[]\n",
    "\n",
    "gaussian_img_t1ce=[]\n",
    "bilateral_img_t1ce=[]\n",
    "img_aniso_filtered_t1ce=[]\n",
    "\n",
    "k=0\n",
    "\n",
    "\n",
    "# Put the values from 10000 for m\n",
    "m=10000\n",
    "n=30500\n",
    "deconvolved_t1ce=[None] * (n-m)\n",
    "    \n",
    "for i in range(m,n):\n",
    "    test_image_t1ce=np.asarray(Image.open(TRAIN_DATASET_PATH + \"{}_t1ce.png\".format(i)))\n",
    "    test_image_t1ce=scaler.fit_transform(test_image_t1ce.reshape(-1, test_image_t1ce.shape[-1])).reshape(test_image_t1ce.shape)\n",
    "\n",
    "    \n",
    "    # img_as_float converts an image from any type to a floating point type in [0, 1], whether it is a color image or not. For example, a (512, 512) image containing uint8 values in the range 0-255 will be converted to a (512, 512) image containing float64 values in the range 0-1.\n",
    "    #converting the image to float type. Since mathematical calculations are required on the image and also mostly, the skimage functions accepts float type image.\n",
    "    noisy_image_t1ce=img_as_float(test_image_t1ce)\n",
    "#     print(test_image_t1ce.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # DENOISING FILTERS\n",
    "    gaussian_img_t1ce.append(nd.gaussian_filter(noisy_image_t1ce, sigma=5))\n",
    "    bilateral_img_t1ce.append(denoise_bilateral(noisy_image_t1ce,sigma_spatial=15))\n",
    "    img_aniso_filtered_t1ce.append(anisotropic_diffusion(noisy_image_t1ce, niter=50, kappa=20, gamma=0.2, option=1))\n",
    "\n",
    "\n",
    "    rng = np.random.default_rng()\n",
    "    psf = np.ones((5, 5)) / 25\n",
    "\n",
    "    t1ce = test_image_t1ce\n",
    "    t1ce = conv2(t1ce, psf, 'same')\n",
    "    t1ce += 0.1 * t1ce.std() * rng.standard_normal(t1ce.shape)\n",
    "\n",
    "    deconvolved_t1ce[k],_=restoration.unsupervised_wiener(t1ce, psf)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Gaussian\n",
    "    \n",
    "    gaussian_cleaned_psnr_t1ce.append(peak_signal_noise_ratio(test_image_t1ce, np.array(gaussian_img_t1ce[k])))\n",
    "    gaussian_cleaned_mse_t1ce.append(mean_squared_error(test_image_t1ce, np.array(gaussian_img_t1ce[k])))\n",
    "    gaussian_cleaned_ssim_t1ce.append(ssim(test_image_t1ce, np.array(gaussian_img_t1ce[k]), multichannel=True, gaussian_weights=True, sigma=1.5, use_sample_covariance=False, data_range=255))\n",
    "    \n",
    "#      gaussian_cleaned_psnr_t1ce.append(peak_signal_noise_ratio(test_image_t1ce[:,:,n_slice], gaussian_img_t1ce[:,:,n_slice]))\n",
    "#     gaussian_cleaned_mse_t1ce.append(mean_squared_error(test_image_t1ce[:,:,n_slice], gaussian_img_t1ce[:,:,n_slice]))\n",
    "#     gaussian_cleaned_ssim_t1ce.append(ssim(test_image_t1ce[:,:,n_slice], gaussian_img_t1ce[:,:,n_slice], multichannel=True, gaussian_weights=True, sigma=1.5, use_sample_covariance=False, data_range=255))\n",
    "    \n",
    "    \n",
    "    #Bilateral\n",
    "    bilateral_cleaned_psnr_t1ce.append(peak_signal_noise_ratio(test_image_t1ce,np.array(bilateral_img_t1ce[k])))\n",
    "    bilateral_cleaned_mse_t1ce.append(mean_squared_error(test_image_t1ce, np.array(bilateral_img_t1ce[k])))\n",
    "    bilateral_cleaned_ssim_t1ce.append(ssim(test_image_t1ce, np.array(bilateral_img_t1ce[k]), multichannel=True, gaussian_weights=True, sigma=1.5, use_sample_covariance=False, data_range=255))\n",
    "    \n",
    "    \n",
    "    #Anisotropic\n",
    "    aniso_cleaned_psnr_t1ce.append(peak_signal_noise_ratio(test_image_t1ce, np.array(img_aniso_filtered_t1ce[k])))\n",
    "    aniso_cleaned_mse_t1ce.append(mean_squared_error(test_image_t1ce, np.array(img_aniso_filtered_t1ce[k])))\n",
    "    aniso_cleaned_ssim_t1ce.append(ssim(test_image_t1ce, np.array(img_aniso_filtered_t1ce[k]), multichannel=True, gaussian_weights=True, sigma=1.5, use_sample_covariance=False, data_range=255))\n",
    "    \n",
    "    #Wiener\n",
    "    wiener_cleaned_psnr_t1ce.append(peak_signal_noise_ratio(test_image_t1ce,np.array(deconvolved_t1ce[k])))\n",
    "    wiener_cleaned_mse_t1ce.append(mean_squared_error(test_image_t1ce, np.array(deconvolved_t1ce[k])))\n",
    "    wiener_cleaned_ssim_t1ce.append(ssim(test_image_t1ce, np.array(deconvolved_t1ce[k]), multichannel=True, gaussian_weights=True, sigma=1.5, use_sample_covariance=False, data_range=255))\n",
    "\n",
    "\n",
    "\n",
    "    k+=1\n",
    "\n",
    "gaussian_sum_psnr_t1ce=0\n",
    "gaussian_sum_mse_t1ce=0\n",
    "gaussian_sum_ssim_t1ce=0\n",
    "\n",
    "\n",
    "bilateral_sum_psnr_t1ce=0\n",
    "bilateral_sum_mse_t1ce=0\n",
    "bilateral_sum_ssim_t1ce=0\n",
    "\n",
    "\n",
    "aniso_sum_psnr_t1ce=0\n",
    "aniso_sum_mse_t1ce=0\n",
    "aniso_sum_ssim_t1ce=0\n",
    "\n",
    "\n",
    "wiener_sum_psnr_t1ce=0\n",
    "wiener_sum_mse_t1ce=0\n",
    "wiener_sum_ssim_t1ce=0\n",
    "\n",
    "for i in range(0,(n-m)):\n",
    "    gaussian_sum_psnr_t1ce +=gaussian_cleaned_psnr_t1ce[i]\n",
    "    gaussian_sum_mse_t1ce +=gaussian_cleaned_mse_t1ce[i]\n",
    "    gaussian_sum_ssim_t1ce +=gaussian_cleaned_ssim_t1ce[i]\n",
    "    \n",
    "    bilateral_sum_psnr_t1ce +=bilateral_cleaned_psnr_t1ce[i]\n",
    "    bilateral_sum_mse_t1ce +=bilateral_cleaned_mse_t1ce[i]\n",
    "    bilateral_sum_ssim_t1ce +=bilateral_cleaned_ssim_t1ce[i]\n",
    "    \n",
    "    aniso_sum_psnr_t1ce +=aniso_cleaned_psnr_t1ce[i]\n",
    "    aniso_sum_mse_t1ce +=aniso_cleaned_mse_t1ce[i]\n",
    "    aniso_sum_ssim_t1ce +=aniso_cleaned_ssim_t1ce[i]\n",
    "    \n",
    "    wiener_sum_psnr_t1ce +=wiener_cleaned_psnr_t1ce[i]\n",
    "    wiener_sum_mse_t1ce +=wiener_cleaned_mse_t1ce[i]\n",
    "    wiener_sum_ssim_t1ce +=wiener_cleaned_ssim_t1ce[i]\n",
    "\n",
    "# print(\"\\n\"*2)\n",
    "\n",
    "\n",
    "# print(\"-\"*10 + \"T1CE\" + \"-\"*10 + \"\\n\"*2)\n",
    "# print(\" \"*10 + \"GAUSSIAN\" + \" \"*10 + \"\\n\")\n",
    "# print(\" \"*5 + \"psnr: {}\".format(gaussian_sum_psnr_t1ce/(n-m)))\n",
    "# print(\" \"*5 + \"mse: {}\".format(gaussian_sum_mse_t1ce/(n-m)))\n",
    "# print(\" \"*5 + \"ssim: {}\".format(gaussian_sum_ssim_t1ce/(n-m)))\n",
    "\n",
    "# print(\"\\n\"*2 + \" \"*10 + \"BILATERAL\" + \" \"*10 + \"\\n\")\n",
    "# print(\" \"*5 + \"psnr: {}\".format(bilateral_sum_psnr_t1ce/(n-m)))\n",
    "# print(\" \"*5 + \"mse: {}\".format(bilateral_sum_mse_t1ce/(n-m)))\n",
    "# print(\" \"*5 + \"ssim: {}\".format(bilateral_sum_ssim_t1ce/(n-m)))\n",
    "\n",
    "# print(\"\\n\"*2 + \" \"*10 + \"ANISOTROPIC\" + \" \"*10 + \"\\n\")\n",
    "# print(\" \"*5 + \"psnr: {}\".format(aniso_sum_psnr_t1ce/(n-m)))\n",
    "# print(\" \"*5 + \"mse: {}\".format(aniso_sum_mse_t1ce/(n-m)))\n",
    "# print(\" \"*5 + \"ssim: {}\".format(aniso_sum_ssim_t1ce/(n-m)))\n",
    "\n",
    "# print(\"\\n\"*2 + \" \"*10 + \"WIENER\" + \" \"*10 + \"\\n\")\n",
    "# print(\" \"*5 + \"psnr: {}\".format(wiener_sum_psnr_t1ce/(n-m)))\n",
    "# print(\" \"*5 + \"mse: {}\".format(wiener_sum_mse_t1ce/(n-m)))\n",
    "# print(\" \"*5 + \"ssim: {}\".format(wiener_sum_ssim_t1ce/(n-m)))\n",
    "\n",
    "print(\"\\n\"*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-17T21:35:20.683461Z",
     "iopub.status.busy": "2022-04-17T21:35:20.683195Z",
     "iopub.status.idle": "2022-04-17T21:35:42.765074Z",
     "shell.execute_reply": "2022-04-17T21:35:42.764372Z",
     "shell.execute_reply.started": "2022-04-17T21:35:20.683431Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "All BraTS multimodal scans are available as NIfTI files (.nii.gz) -> commonly used medical imaging format to store brain imagin data obtained using MRI and describe different MRI settings\n",
    "T1: T1-weighted, native image, sagittal or axial 2D acquisitions, with 1–6 mm slice thickness.\n",
    "T1ce: T1-weighted, contrast-enhanced (Gadolinium) image, with 3D acquisition and 1 mm isotropic voxel size for most patients.\n",
    "T2: T2-weighted image, axial 2D acquisition, with 2–6 mm slice thickness.\n",
    "FLAIR: T2-weighted FLAIR image, axial, coronal, or sagittal 2D acquisitions, 2–6 mm slice thickness.\n",
    "#Note: Segmented file name in Folder 355 has a weird name. Rename it to match others.\n",
    "\"\"\"\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import glob\n",
    "import random\n",
    "# from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "from tifffile import imsave\n",
    "from skimage import img_as_float\n",
    "from skimage.metrics import peak_signal_noise_ratio\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage import io\n",
    "from scipy import ndimage as nd\n",
    "from skimage.restoration import (denoise_tv_chambolle, denoise_bilateral,denoise_wavelet, estimate_sigma)\n",
    "from medpy.filter.smoothing import anisotropic_diffusion\n",
    "from scipy.signal import wiener\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from skimage.metrics import mean_squared_error\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from PIL import Image\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##########################\n",
    "#This part of the code to get an initial understanding of the dataset.\n",
    "#################################\n",
    "#PART 1: Load sample images and visualize\n",
    "#Includes, dividing each image by its max to scale them to [0,1]\n",
    "#Converting mask from float to uint8\n",
    "#Changing mask pixel values (labels) from 4 to 3 (as the original labels are 0, 1, 2, 4)\n",
    "#Visualize\n",
    "###########################################\n",
    "#View a few images\n",
    "\n",
    "#Note: Segmented file name in Folder 355 has a weird name. Rename it to match others.\n",
    "\n",
    "\n",
    "# Setting up of image path and scaling the image\n",
    "gaussian_img_t1ce=[]\n",
    "bilateral_img_t1ce=[]\n",
    "img_aniso_filtered_t1ce=[]\n",
    "\n",
    "k=0\n",
    "\n",
    "\n",
    "# Put the values from 10000 for m\n",
    "m=10000\n",
    "n=10002\n",
    "deconvolved_t1ce=[None] * (n-m)\n",
    "    \n",
    "for i in range(m,n):\n",
    "    test_image_t1ce=np.asarray(Image.open(TRAIN_DATASET_PATH + \"{}_t1ce.png\".format(i)))\n",
    "    test_image_t1ce=scaler.fit_transform(test_image_t1ce.reshape(-1, test_image_t1ce.shape[-1])).reshape(test_image_t1ce.shape)\n",
    "\n",
    "    \n",
    "    # img_as_float converts an image from any type to a floating point type in [0, 1], whether it is a color image or not. For example, a (512, 512) image containing uint8 values in the range 0-255 will be converted to a (512, 512) image containing float64 values in the range 0-1.\n",
    "    #converting the image to float type. Since mathematical calculations are required on the image and also mostly, the skimage functions accepts float type image.\n",
    "    noisy_image_t1ce=img_as_float(test_image_t1ce)\n",
    "    print(test_image_t1ce.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # DENOISING FILTERS\n",
    "    gaussian_img_t1ce.append(nd.gaussian_filter(noisy_image_t1ce, sigma=5))\n",
    "    bilateral_img_t1ce.append(denoise_bilateral(noisy_image_t1ce,sigma_spatial=15))\n",
    "    img_aniso_filtered_t1ce.append(anisotropic_diffusion(noisy_image_t1ce, niter=50, kappa=20, gamma=0.2, option=1))\n",
    "\n",
    "\n",
    "    rng = np.random.default_rng()\n",
    "    psf = np.ones((5, 5)) / 25\n",
    "\n",
    "    t1ce = test_image_t1ce\n",
    "    t1ce = conv2(t1ce, psf, 'same')\n",
    "    t1ce += 0.1 * t1ce.std() * rng.standard_normal(t1ce.shape)\n",
    "\n",
    "    deconvolved_t1ce[k],_=restoration.unsupervised_wiener(t1ce, psf)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Gaussian\n",
    "    print(\"\\n\"*2)\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    print(\"Gaussian\")\n",
    "    plt.subplot(233)\n",
    "    plt.imshow(gaussian_img_t1ce[k], cmap='gray')\n",
    "    gaussian_cleaned_psnr = peak_signal_noise_ratio(test_image_t1ce, gaussian_img_t1ce[k])\n",
    "    gaussian_cleaned_mse = mean_squared_error(test_image_t1ce, gaussian_img_t1ce[k])\n",
    "    gaussian_cleaned_ssim= ssim(test_image_t1ce, gaussian_img_t1ce[k], multichannel=True, gaussian_weights=True, sigma=1.5, use_sample_covariance=False, data_range=255)\n",
    "    print(\"PSNR of cleaned image = \", gaussian_cleaned_psnr)\n",
    "    print(\"MSE of cleaned image = \", gaussian_cleaned_mse)\n",
    "    print(\"SSIM of cleaned image = \", gaussian_cleaned_ssim)\n",
    "    print(\"\\n\"*2)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "    # Bilateral\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    print(\"Bilateral\")\n",
    "    plt.subplot(233)\n",
    "    plt.imshow(bilateral_img_t1ce[k], cmap='gray')\n",
    "    bilateral_cleaned_psnr = peak_signal_noise_ratio(test_image_t1ce,bilateral_img_t1ce[k])\n",
    "    bilateral_cleaned_mse = mean_squared_error(test_image_t1ce, bilateral_img_t1ce[k])\n",
    "    bilateral_cleaned_ssim= ssim(test_image_t1ce, bilateral_img_t1ce[k], multichannel=True, gaussian_weights=True, sigma=1.5, use_sample_covariance=False, data_range=255)\n",
    "    print(\"PSNR of cleaned image = \", bilateral_cleaned_psnr)\n",
    "    print(\"MSE of cleaned image = \", bilateral_cleaned_mse)\n",
    "    print(\"SSIM of cleaned image = \", bilateral_cleaned_ssim)\n",
    "    print(\"\\n\"*2)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "    #Anistropic\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    print(\"Anistropic\")\n",
    "    plt.subplot(233)\n",
    "    plt.imshow(img_aniso_filtered_t1ce[k], cmap='gray')\n",
    "    aniso_cleaned_psnr = peak_signal_noise_ratio(test_image_t1ce, img_aniso_filtered_t1ce[k])\n",
    "    aniso_cleaned_mse = mean_squared_error(test_image_t1ce, img_aniso_filtered_t1ce[k])\n",
    "    aniso_cleaned_ssim= ssim(test_image_t1ce, img_aniso_filtered_t1ce[k], multichannel=True, gaussian_weights=True, sigma=1.5, use_sample_covariance=False, data_range=255)\n",
    "    print(\"PSNR of cleaned image = \", aniso_cleaned_psnr)\n",
    "    print(\"MSE of cleaned image = \", aniso_cleaned_mse)\n",
    "    print(\"SSIM of cleaned image = \", aniso_cleaned_ssim)\n",
    "    print(\"\\n\"*2)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "    # Wiener\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    print(\"Wiener\")\n",
    "    plt.subplot(233)\n",
    "    plt.imshow(deconvolved_t1ce[k], cmap='gray')\n",
    "    wiener_cleaned_psnr = peak_signal_noise_ratio(test_image_t1ce,deconvolved_t1ce[k])\n",
    "    wiener_cleaned_mse = mean_squared_error(test_image_t1ce, deconvolved_t1ce[k])\n",
    "    wiener_cleaned_ssim= ssim(test_image_t1ce, deconvolved_t1ce[k], multichannel=True, gaussian_weights=True, sigma=1.5, use_sample_covariance=False, data_range=255)\n",
    "    print(\"PSNR of cleaned image = \", wiener_cleaned_psnr)\n",
    "    print(\"MSE of cleaned image = \", wiener_cleaned_mse)\n",
    "    print(\"SSIM of cleaned image = \", wiener_cleaned_ssim)\n",
    "    print(\"\\n\"*2)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "    # Raw Images\n",
    "\n",
    "    print(\"\\n\"*4)\n",
    "    print(\"RAW IMAGES\")\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.subplot(233)\n",
    "    plt.imshow(test_image_t1ce, cmap='gray')\n",
    "    plt.title('Image t1ce')\n",
    "    plt.show()\n",
    "    \n",
    "    k+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
